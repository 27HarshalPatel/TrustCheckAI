# ğŸš€ TrustCheckAI â€” Bias and Compliance Detaction Platform

<p align="center">
  <img src="./TrustCheckAI-demo.gif" width="650">
</p>

TrustCheckAI is an end-to-end bias and compliance auditing, explainability, and model-monitoring platform designed to evaluate bias, mitigate discrimination, explain model decisions, and continuously monitor deployed machine learning systems using Prometheus & Grafana.

It provides real-time dashboards, fairness metrics, model explainability (LIME), drift detection, automated PDF reporting, and user feedback collection â€” all wrapped in a modern Streamlit UI and containerized for seamless deployment.

---

## ğŸ“‘ Table of Contents
- âœ¨ Features
- ğŸ§° Technical Stack
- ğŸ“š Supported Datasets
- ğŸ— System Architecture
- ğŸ” Compliance, Fairness & Security
- ğŸ¨ Human-Centered Design (HCI)
- âš™ï¸ Installation & Setup
- ğŸ§ª Usage Workflow
- ğŸ“Š Prometheus Metrics & Grafana Dashboards
- ğŸ“‰ Drift Detection
- ğŸ“˜ PDF Report Generation
- ğŸ¥ Demonstration
- ğŸ›£ Roadmap
- ğŸ“„ Citations
- ğŸ¤ Acknowledgements

---

## âœ¨ Features

### ğŸŸ£ Bias Detection (AIF360)
- Statistical Parity Difference  
- Disparate Impact  
- Equal Opportunity Difference  
- Equalized Odds  
- Demographic Parity Ratio   

### ğŸ§  Explainability (XAI)
- **LIME** â€“ local explanations per prediction  

### ğŸ“‰ Drift Detection
- Kolmogorovâ€“Smirnov (KS) Test  

### âš™ Model Training & Evaluation
- Logistic Regression  
- Random Forest  
- 5-fold cross-validation  

### ğŸ” Real-Time Monitoring & Alerting
- Prometheus metric exporter  
- Grafana dashboards  
- Automated Slack alerts for accuracy/fairness drift  

### ğŸ“„ Automatic PDF Reporting
- Full bias report  
- Model performance summary  

### ğŸ–¥ Modern Streamlit UI
- Clean, intuitive layout  
- File upload, analysis, visualization  
- User feedback

### ğŸ³ Fully Containerized
- Streamlit  
- Prometheus  
- Grafana  
- Docker Compose orchestration  

---

## ğŸ§° Technical Stack

### ML & Fairness
- Python 3.9+  
- Scikit-learn  
- AIF360  
- LIME  

### Monitoring & Observability
- Prometheus  
- Grafana  

### Frontend
- Streamlit  

### DevOps
- Docker  
- Docker Compose  
- GitHub  

---

## ğŸ“š Supported Datasets

### COMPAS â€“ Criminal Justice  
### User Uploaded Structured Dataset

---

## ğŸ— System Architecture

```
User Upload â†’ Preprocessing â†’ AIF360 Bias Detection 
        â†’ Model Training â†’ LIME â†’ Drift Detection
        â†’ Prometheus Exporter â†’ Grafana Dashboards & Alerts
```

---

## ğŸ” Compliance, Fairness & Security
- Regulatory alignment (EEOC, Justice fairness)  
- Differential privacy  
- Ethical AI lifecycle tracking  
- Secure isolated containers  

---

## ğŸ¨ HCI Principles
- Accessible charts  
- Colorblind-safe design  
- Clear fairness/performance separation  
- Prototyped user flows  

---

## âš™ï¸ Installation & Setup

```bash
git clone https://github.com/27HarshalPatel/TrustCheckAI.git
cd TrustCheckAI
docker-compose up --build
```

Access:
- Streamlit â†’ http://localhost:8501  
- Prometheus â†’ http://localhost:9090  
- Grafana â†’ http://localhost:3000  

---

## ğŸ§ª Usage Workflow
1. Upload CSV  
2. Run fairness analysis  
3. Train models  
4. View LIME 
5. Generate PDF  
6. Monitor in Grafana  
7. Receive alerts if Accuracy falls below 70%

---

## ğŸ“Š Prometheus Metrics
- upload_counter  
- analysis_counter  
- accuracy_gauge  
- feedback_ratings_counter  
- feedback_comments_counter  

---

## ğŸ“‰ Drift Detection
- KS Test 

---

## ğŸ“˜ PDF Report Generation
Includes fairness metrics and performance summary.

---

## ğŸ¥ Demonstration

<p align="center">
  <img src="./TrustCheckAI-demo.gif" width="700">
</p>

---

## ğŸ›£ Roadmap
- Fairlearn integration  
- Kubernetes deployment  
- Extended fairness metrics  

---

## ğŸ“„ Citations
- IBM AIF360  
- COMPAS Dataset  

---

## ğŸ¤ Acknowledgements
- University of Florida  
- HiPerGator Computing  
- Open-source community  
